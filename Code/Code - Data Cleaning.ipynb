{
 "metadata": {
  "name": "",
  "signature": "sha256:4f46d245fd232d672024506002ebd5aa7e5ce46bf36e4c2b8fdd8de1399636a6"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "All Code For Data Cleaning"
     ]
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "1. Summary"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The purpose of this is to show the main data cleaning that was used for the other IPython notebooks. All the other notebooks still contain general subsetting and aggregation. This code includes the library, create_list, which contains the two functions make_empty_dataframe and clean_date. The code for creating the .csv files for each individual team is also included."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# This is where all the datasets for the project are contained. They will also be added to the github file.\n",
      "cd C:\\tmp"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Import all libraries and have plots show in their respective blocks.\n",
      "import pandas as pd\n",
      "import datetime\n",
      "import time\n",
      "import numpy as np\n",
      "import matplotlib as mpl\n",
      "import matplotlib.pyplot as plt\n",
      "import seaborn as sns\n",
      "%matplotlib inline"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Reads the .csv data\n",
      "df = pd.read_csv(\"june_final.csv\", header=None, names=['id', 'name', 'followers', 'current_viewers', 'date_time'])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Extracts individual pieces to be used later for the new datetime\n",
      "df['years'] = pd.DatetimeIndex(df['date_time']).year\n",
      "df['months'] = pd.DatetimeIndex(df['date_time']).month\n",
      "df['days'] = pd.DatetimeIndex(df['date_time']).day\n",
      "df['hours'] = pd.DatetimeIndex(df['date_time']).hour\n",
      "df['minutes'] = pd.DatetimeIndex(df['date_time']).minute"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "2. Library: create_list"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "This function creates a dataframe with an index that ranges from 5/30/2015 - 6/30/2015 where each value is a zero.\n",
      "This dataframe is created to later combine with other dataframes where downtime is needed - giving a \n",
      "complete time series. It is included in the create_list library."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def make_empty_dataframe(df):\n",
      "    date_tmp = pd.date_range(start=datetime.datetime(2015, 5, 30), end=datetime.datetime(2015, 6, 30)).tolist()\n",
      "    date_df = pd.DataFrame(date_tmp).reset_index()\n",
      "    date_df.columns = ('index', 'date')\n",
      "    date_list = pd.to_datetime(date_df['date']).tolist()\n",
      "\n",
      "    datetime_list = []\n",
      "    hour_list = np.arange(0,24)\n",
      "    min_list = (0, 10, 20, 30, 40, 50)\n",
      "\n",
      "    for x in date_list:\n",
      "        day1 = x.day\n",
      "        month1 = x.month\n",
      "        year1 = x.year\n",
      "\n",
      "        for y in hour_list:\n",
      "            for z in min_list:\n",
      "                datetime_list.append(datetime.datetime(year1, month1, day1, y, z))\n",
      "    \n",
      "    datetime_df = pd.DataFrame(index=datetime_list, columns=['A'])\n",
      "    datetime_df.fillna(0, inplace=True)\n",
      "\n",
      "    return datetime_d"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "This function is included in the create_list library.\n",
      "The purpose of this function is to clean the minutes so that it is either 00, 10, 20, 30, 40, 50\n",
      "and then placed into a dataframe column as a datetime object."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def clean_date(df):\n",
      "    zeroes = np.arange(0, 10)\n",
      "    tens = np.arange(10, 20)\n",
      "    twenties = np.arange(20, 30)\n",
      "    thirties = np.arange(30, 40)\n",
      "    fourties = np.arange(40, 50)\n",
      "    fifties = np.arange(50, 60)\n",
      "    df['minutes'].replace(fourties, 40, inplace=True)\n",
      "    df['minutes'].replace(zeroes, 0, inplace=True)\n",
      "    df['minutes'].replace(tens, 10, inplace=True)\n",
      "    df['minutes'].replace(twenties, 20, inplace=True)\n",
      "    df['minutes'].replace(thirties, 30, inplace=True)\n",
      "    df['minutes'].replace(fifties, 50, inplace=True)\n",
      "\n",
      "    for index, row in df.iterrows():\n",
      "        df.loc[index, 'test'] = datetime.datetime(row['years'], row['months'], row['days'], row['hours'], row['minutes'])\n",
      "\n",
      "    return df"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def agg_df(df, by=[None]):\n",
      "    avg_viewer = df.groupby(by=by)['current_viewers'].mean()\n",
      "    avg_viewer_df = pd.DataFrame(avg_viewer).reset_index()\n",
      "    avg_viewer_df.rename(columns={'current_viewers':'mean_viewers'}, inplace=True)\n",
      "    \n",
      "    avg_follower = df.groupby(by=by)['followers'].mean()\n",
      "    avg_follower_df = pd.DataFrame(avg_follower).reset_index()\n",
      "    avg_follower_df.rename(columns={'followers':'mean_followers'}, inplace=True)\n",
      "\n",
      "    count_stream = df.groupby(by=by)['current_viewers'].count()\n",
      "    count_stream_df = pd.DataFrame(count_stream).reset_index()\n",
      "    count_stream_df.rename(columns={'current_viewers':'count'}, inplace=True)\n",
      "\n",
      "    tmp_df = pd.merge(avg_viewer_df, avg_follower_df, on=by)\n",
      "    combined_df = pd.merge(tmp_df, count_stream_df, on=by)\n",
      "\n",
      "    return combined_df"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "3. Create Team Datasets"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# List of each players' twitch.tv name\n",
      "archon = ['amazhs', 'deernadia', 'hero_firebat', 'xixo', 'zalaehs', 'orange_hs', 'backspacehs', 'purpledrank_hs']\n",
      "c9 = ['gnimsh', 'itshafu', 'kolento', 'ek0p', 'strifecro', 'tidesoftime', 'massansc']\n",
      "complexity = ['superjj102', 'hsdogdog', 'thejordude', 'ryzentv']\n",
      "liquid = ['savjz', 'neirea', 'sjow']\n",
      "nihilum = ['thijshs', 'lifecoach1981', 'lotharhs', 'radu_hs']\n",
      "tempostorm = ['reynad27', 'gaarabestshaman', 'ratsmah', 'reckful', 'hyp3d', 'eloise_ailv', 'justsaiyanhs']\n",
      "tsm = ['nl_kripp', 'trumpsc']"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Make individual team datasets\n",
      "archon_df = df[df['name'].isin(archon)]\n",
      "c9_df = df[df['name'].isin(c9)]\n",
      "complexity_df = df[df['name'].isin(complexity)]\n",
      "liquid_df = df[df['name'].isin(liquid)]\n",
      "nihilum_df = df[df['name'].isin(nihilum)]\n",
      "tempostorm_df = df[df['name'].isin(tempostorm)]\n",
      "tsm_df = df[df['name'].isin(tsm)]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Make separate files for each team\n",
      "archon_df.to_csv('archon.csv', columns=('name', 'followers', 'current_viewers', 'days', 'hours', 'minutes', 'test'))\n",
      "c9_df.to_csv('c9.csv', columns=('name', 'followers', 'current_viewers', 'days', 'hours', 'minutes', 'test'))\n",
      "complexity_df.to_csv('complexity.csv', columns=('name', 'followers', 'current_viewers', 'days', 'hours', 'minutes', 'test'))\n",
      "liquid_df.to_csv('liquid.csv', columns=('name', 'followers', 'current_viewers', 'days', 'hours', 'minutes', 'test'))\n",
      "nihilum_df.to_csv('nihilum.csv', columns=('name', 'followers', 'current_viewers', 'days', 'hours', 'minutes', 'test'))\n",
      "tempostorm_df.to_csv('tempostorm.csv', columns=('name', 'followers', 'current_viewers', 'days', 'hours', 'minutes', 'test'))\n",
      "tsm_df.to_csv('tsm.csv', columns=('name', 'followers', 'current_viewers', 'days', 'hours', 'minutes', 'test'))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Remove all the tournament data to compare with previous boxplot\n",
      "tournament_list = ['dreamhackhs', 'viagamehs', 'esl_hearthstone', 'tempo_storm', 'wca_america', 'nvidia', 'nvidiafrance',\n",
      "                   'starladder_hs_ru', 'starladder_hs_eu', 'vulcunhs', 'viagamehs_ru', 'onenationofgamers', 'stormstudio_hs_ru', \n",
      "                   'hkesportstv', 'hearthstonefr', 'readyuptv', 'pvplive']\n",
      "\n",
      "# ~ -> not, isin -> in used for lists\n",
      "no_tourn_df = df[~df['name'].isin(tournament_list)]\n",
      "no_tourn_df.to_csv('no_tourn.csv')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "df.to_csv('main.csv')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}